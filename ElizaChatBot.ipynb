{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "The program build is an Eliza chatbot that engages in a dialogue with the user. Eliza plays the role of a psychotherapist. Eliza chatbot takes the input from the user and responds with a meaningful message. The chatbox looks for text pattern such as \"I feel X\" based on the keywords within the input using \"word spotting\" (such as 'kill', 'no', 'happy', 'angry', 'remember') and responds with a matching comment, such as \"I understand. Why do you feel X\". An example for this would be if the user enters \"I feel sad\", then the response would be \"Sorry to hear that, tell me more.\". The program is robust enough in case it is not able to spot any word, it will return with a default message.\n",
    "\n",
    "Chatbots were created as an Artificial Intelligence program to chat with users and provide them with information and support instead of having a human being present. Eliza uses a script that is simulated to emulate a psychotherapist.\n",
    "\n",
    "We have included algorithms such as word spotting, wordnet, sentence transformation, lemmatizations, tokenization, POS tagging to execute Eliza successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Usage and Example\n",
    "\n",
    "Additional Functionality : \n",
    "1. The bemused word is not present in the pre-defined lost dictionary. But the program is using wordnet. synsets function to check for all the synonyms of the lost word. And based on that it will respond to user \n",
    "\n",
    "2. We used POS tagging to find out noun, verb, adjective present in the user input, and based on that we are replying to the user.\n",
    "\n",
    "\n",
    "# Below is the example:\n",
    "\n",
    "\n",
    "[Eliza]: Hi I am psychotherapist! What is your name?\n",
    "\n",
    "My name is ivaan\n",
    "\n",
    "[Eliza]: Hi Ivaan, how are you feeling?\n",
    "\n",
    "I am feeling bemused\n",
    "\n",
    "[Eliza]:  I am sorry to hear that. Feeling lost can be a painful experience. How can I help you\n",
    "\n",
    "I want to kill someone\n",
    "\n",
    "[Eliza]:  Have you talked to your friends about kill thoughts?\n",
    "\n",
    "no\n",
    "\n",
    "[Eliza]:  Are you sure?\n",
    "\n",
    "yes\n",
    "\n",
    "[Eliza]:  I understand. Tell me more\n",
    "\n",
    "tell me about you\n",
    "\n",
    "[Eliza]:  Why do you want to know about me?\n",
    "\n",
    "I feel powerful\n",
    "\n",
    "[Eliza]:  Intresting! Tell me more about your feelings.\n",
    "\n",
    "I feel pathetic\n",
    "\n",
    "[Eliza]: Any idea why you are feeling like pathetic.\n",
    "\n",
    "I have no idea\n",
    "\n",
    "[Eliza]:  Why no?\n",
    "\n",
    "I don't know\n",
    "\n",
    "[Eliza]:  Do you want to talk more about it?\n",
    "\n",
    "bye Eliza\n",
    "\n",
    "[Eliza]: Bye Ivaan ! Take care"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "Start :\n",
    "    1. Eliza chatbot welcomes the user and asks for his name.\n",
    "    2. Eliza asks the user about his feelings.\n",
    "    3. Based on user response(happy, sad, lost), Eliza greets the user.\n",
    "    4. Program calls the conversation function and enters the while loop and decides the next course of action        based on the user input.\n",
    "        - Option 1: If the user wants to quit:\n",
    "                    Eliza repond with the Bye message and exit the program\n",
    "        - Option 2: if the user wants to continue the conversation:\n",
    "                    a. Eliza replaces words from user input like I'm to I am , he's to he and combined back \n",
    "                    to user response\n",
    "                    b. Eliza change the first noun pronoun to second noun pronoun such as from \"you\" to \"I\"\n",
    "                    , \"me\" to \"you\" , \"I\" to \"you\".\n",
    "                    c. Eliza takes the keywords within the input using \"word spotting\" and respond back with\n",
    "                    pre written replies\n",
    "                    d. If the user wants to talk further regarding few responses that include crave, feel, \n",
    "                    like Eliza calls function responses_basic_questions, that is using POS Tagging and check\n",
    "                    whether the sentence contains noun, adjectives or verb and based on that it will respond\n",
    "                    back to the user.\n",
    "                    e. If Eliza is not able to find the matching keyword, the program replies with the\n",
    "                    default messages.\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. N. (2020, May 6). norib016/Developing_A_Chatbot_Python. GitHub. https://github.com/norib016/Developing_A_Chatbot_Python\n",
    "    \n",
    "2. Liao, L. (2021b, June 8â€“10). Regular Expression & Python RegEx [Prsentation]. Regular Expression & Python RegEx, Fairfax, USA.\n",
    "\n",
    "3. Jurafsky, D., & H. Martin., J. (2020). Chatbots & Dialogue Systems. Speech and Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported libraries\n",
    "\n",
    "The libraries used to bhuild chatbot eliza requires mostly NLP toolkit package.\n",
    "In addition it used few more libraries such as re (for regex function), string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for getting user name\n",
    "\n",
    "The function will introduce itself to the user and ask for the user name. If the user input with more than one word, it uses the last word as the user name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking user name:\n",
    "\n",
    "def username():\n",
    "    print('[Eliza]: Hi I am psychotherapist! What is your name?')\n",
    "    \n",
    "    user_response = input().lower()\n",
    "    tokens = word_tokenize(user_response) \n",
    "    \n",
    "    if(tokens==''):\n",
    "        user_response='User'    #Default user name\n",
    "    elif(len(tokens)>1):\n",
    "        user_response=tokens[-1]   #Taking last name, if name has more than 1 word\n",
    "    else:\n",
    "        user_response = user_response\n",
    "        \n",
    "    user_name = user_response.title()   #Convert username in title form, with first letter as capital\n",
    "    \n",
    "    return user_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response dictionary\n",
    "\n",
    "The program takes the input from the user and checks for the keyword in the response dictionary. Based on word spotted, it will give a meaningful response to the user. Below is the dictionary contains different responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building responses\n",
    "\n",
    "#The responses dictionary consist of greeting response\n",
    "\n",
    "responses={'happy_greeting':['I am glad to hear that. How can I help you today?', \n",
    "                             'Happy to hear. How can I help you?'],\n",
    "          'sad_greeting':['I am sorry to hear that. How can I help you today?',\n",
    "                          'I am sorry to hear that. What happen?'],\n",
    "          'lost_greeting':['I am sorry to hear that. Feeling lost can be a painful experience. How can I help you',\n",
    "                           'I understand, let us talk through a plan.'],\n",
    "          'default':['I did not understand. Could you please type again?','Tell me more.']}\n",
    "\n",
    "#The pyscoresponses dictionary consists of user conversation responses\n",
    "\n",
    "pyscoresponses ={r'.*(feel).*':[r\"Why don't you tell me more about your \\1ings.\", #\\1 will replace with word from the user response\n",
    "                                           r\"Intresting! Tell me more about your \\1ings.\"],\n",
    "                 \n",
    "                 r'(.*)(crave|like|craving|liking|craved|liked)(.*)':[r\"Do \\1really \\2\\3?\"],\n",
    "                                          \n",
    "                 \n",
    "                 r'.*(kill|murder|suicide|harm|hurt).*':[r\"Why you are feeling this way? Talk to me.\",\n",
    "                                               r\"Have you talked to your family about \\1 thoughts?\",\n",
    "                                               r\"Have you talked to your friends about \\1 thoughts?\",\n",
    "                                                r\"Please don't hurt yourself or anyone around you. Please call 911 for emergency!\",\n",
    "                                                r\"I hope you will keep talking to me\"],\n",
    "                 \n",
    "                 r\"(.*)(can't|cant|can no+t+)(.*)\":[r\"How do you know you can't\\3 ?\", \n",
    "                                  r\"Perhaps you could\\3 if you tried.\"],\n",
    "                 \n",
    "                 r'.*(happy).*':[r\"That is good. What is making you happy?\",\n",
    "                                r\"Can you tell me why you are happy?\",\n",
    "                                r\"Tell me more about that.\",\n",
    "                                r\"Sounds good. Tell me more why you are happy?\"],\n",
    "                 \n",
    "                 r'.*(sad).*':[r\"Sorry to hear that, tell me more.\",\n",
    "                              r\"Do you want to discuss about it?\"],\n",
    "                 \n",
    "                 r'.*(angry).*':[r\"Sorry to hear that. Let's discuss further?\"],\n",
    "                 \n",
    "                 r'.*(desire).*':[r\"What would it mean to you if you got \\1 ?\", \n",
    "                                  r\"What is the real reason behind \\1 ?\"],\n",
    "                 \n",
    "                 r'(.*)(was (you|I))(.*)':[r\"What if you were \\3 ?\", \n",
    "                                 r\"Do you think you were \\3 ?\"],\n",
    "                 \n",
    "                 r'(.*)(remember)(.*)':[r\"Do you often think about\\3?\", \n",
    "                                    r\"Does thinking of\\3 bring anything else to mind?\"],\n",
    "                 \n",
    "                 r'(.*)(if)(.*)':[r\"Do you think that its likely that\\3 can happen?\", \n",
    "                              r\"Do you wish that\\3?\"],\n",
    "                 \n",
    "                 r'(.*)(ok|okay|okie)(.*)':[r\"Sounds good! Tell me more about you?\",\n",
    "                                       r\"Do you want to talk more about it?\"],\n",
    "                 \n",
    "                 r'.*(sure).*':[r\"Tell me more about you?\",\n",
    "                                r\"Sounds good! You want to talk more?\",\n",
    "                                r\"Please go on.\",\n",
    "                                r\"Please carry on.\"],\n",
    "                 \n",
    "                 r'.*(sorry).*':[r\"Please do not apologize. I understand your situation.\",\n",
    "                                r\"It did not bother me. I am listening, please continue.\",\n",
    "                                r\"Apologies are not required.\"],\n",
    "                 \n",
    "                 r'.*(no+).*':[r\"Why no?\",\n",
    "                                r\"Why not?\",\n",
    "                               r\"Are you sure?\"],\n",
    "                 \n",
    "                 r'.*(yes?).*':[r\"You seem to be positive.\",\n",
    "                               r\"I see.\",\n",
    "                               r\"I understand.\",\n",
    "                               r\"I understand. Tell me more\",\n",
    "                               r\"You seem to be positive.\"],\n",
    "                 \n",
    "                 r'.*(about (me|you|I)).*':[r\"We are discussing you, not me.\",\n",
    "                                        r\"Oh, I?\",\n",
    "                                        r\"Why do you want to know about me?\"],\n",
    "                 \n",
    "                 r'(.*)(need)(.*)':[r\"Could you tell me why do you need\\3?\",\n",
    "                                r\"Would it really help you if you get\\3?\",\n",
    "                                 r\"Are you sure you need\\3?\"],\n",
    "                 \n",
    "                 r'(.*)':[r\"I do not understand. Could you please type again?\",\n",
    "                          r\"I do not understand. Please elaborate\",\n",
    "                         r\"I am trouble following you. Could you please elaborate.\"]\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greeting function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greeting function consists of three parts.\n",
    "1. Greeting dictionary has few keywords and greeting_dict() is using wordnet library to get more synonyms for the given keywords. For eg. for the keyword \"happy\", wordnet will use synset function to find out all the synonyms for the word happy. This function will return a dictionary of all the synonyms.\n",
    "2. Created \"greeting_intent_dict()\" function. This function will use dictionary created by greeting_dict function. It will append boundary(\\b) and regrex expression (.*) in all the words present in the dictionary i.e. \".*\\\\b'+words+'\\\\b.*\". It will create a common dictionary named as keywords and it will contain three different intent (happy_greeting, sad_greeting and lost_greeting). \n",
    "keywords_dict compile regex dynamically with the keywords present in the dictionary.\n",
    "3. Based on the user response of \"how the user is feeling today?\". The function will check the dictionary responses. It will search for the keyword and based on that it responds to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for creating dictionary for getting greeting synonyms\n",
    "\n",
    "\n",
    "def greeting_dict():\n",
    "    global healthy_response\n",
    "    global non_healthy_response\n",
    "    global lost_response\n",
    "    \n",
    "    ## Created three different response type that is happy response(healthy response), \n",
    "    ##sad response(non healthy response) and lost response\n",
    "    \n",
    "    healthy_response=['happy','healthy','good','awesome','great','lively']\n",
    "    non_healthy_response = ['sad','sick','low','healthy low']\n",
    "    lost_response = ['lost','stray','disoriented']\n",
    "\n",
    "\n",
    "    ##Creating dictionary that will contain synonyms of healthy, not healthy and lost words\n",
    "    \n",
    "    dict_syn_healthy={}\n",
    "    dict_syn_non_healthy={}\n",
    "    dict_syn_lost={}\n",
    "    \n",
    "    synonym_healthy=[]\n",
    "    synonym_nonhealthy=[]\n",
    "    synonym_lost=[]\n",
    "    \n",
    "\n",
    "    for healthy_word in healthy_response:\n",
    "        for synset in wordnet.synsets(healthy_word): ## synset function will return the synonyms of words present in healthy_response\n",
    "            for lemma in synset.lemmas(): ##Returns the lemma word\n",
    "                synonym_healthy.append(lemma.name())\n",
    "               \n",
    "        dict_syn_healthy[healthy_word]=set(synonym_healthy) \n",
    "\n",
    "    for nonhealthy_word in non_healthy_response:\n",
    "        for syn in wordnet.synsets(nonhealthy_word): ##synset function will return the synonyms of words present in nonhealthy_response\n",
    "            for lemma1 in syn.lemmas():\n",
    "                synonym_nonhealthy.append(lemma1.name())\n",
    "                \n",
    "        dict_syn_non_healthy[nonhealthy_word]=set(synonym_nonhealthy)\n",
    "        \n",
    "    for lost_word in lost_response:\n",
    "        for syn in wordnet.synsets(lost_word):  ##synset function will return the synonyms of words present in lost_word\n",
    "            for lemma2 in syn.lemmas():\n",
    "                    synonym_lost.append(lemma2.name())\n",
    "            dict_syn_lost[lost_word]=set(synonym_lost)\n",
    "            \n",
    "    ## the function will return dictionary of all the synonyms and the actual word  \n",
    "    return dict_syn_non_healthy, synonym_nonhealthy,dict_syn_healthy, synonym_healthy, dict_syn_lost, synonym_lost \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building dictionary of intent and keyword\n",
    "\n",
    "def greeting_intent_dict():\n",
    "    keywords = {}\n",
    "    keywords_dict ={}\n",
    "\n",
    "    keywords['happy_greeting'] = []\n",
    "\n",
    "    dict_syn_non_healthy, synonym_nonhealthy,dict_syn_healthy, synonym_healthy, dict_syn_lost, synonym_lost  = greeting_dict()\n",
    "\n",
    "    for word in healthy_response:\n",
    "        for words in list(dict_syn_healthy[word]):\n",
    "            keywords['happy_greeting'].append('.*\\\\b'+words+'\\\\b.*') # used to append boundary and regex(.*) in all the words from dictionary dict_syn_healthy \n",
    "\n",
    "    keywords['sad_greeting']=[]\n",
    "\n",
    "    for word in non_healthy_response:\n",
    "        for words in list(dict_syn_non_healthy[word]):\n",
    "            keywords['sad_greeting'].append('.*\\\\b'+words+'\\\\b.*') # used to append boundary and regex(.*) in all the words from dictionary dict_syn_non_healthy \n",
    "\n",
    "    keywords['lost_greeting']=[]\n",
    "    \n",
    "    for word in lost_response:\n",
    "        for words in list(dict_syn_lost[word]):\n",
    "            keywords['lost_greeting'].append('.*\\\\b'+words+'\\\\b.*') # used to append boundary and regex(.*) in all the words from dictionary dict_syn_lost \n",
    "\n",
    "    for intent, keys in keywords.items():\n",
    "        keywords_dict[intent] = re.compile('|'.join(keys))\n",
    "       \n",
    "    # The function will return keywords_dict that will compile the regex dynamically\n",
    "    return keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to greet the user based on his response\n",
    "\n",
    "\n",
    "def greeting(user_name):\n",
    "    print('[Eliza]: Hi {}, how are you feeling?'.format(user_name.title()))\n",
    "    \n",
    "    matched_intent = None\n",
    "    user_response = input().lower()  # Change user input in lower case\n",
    "    key= 'default'\n",
    "    \n",
    "    keywords_dict = greeting_intent_dict() #Call function greeting_intent_dict that return dictionary that will compile the regex dynamically\n",
    "    \n",
    "    for intent, pattern in keywords_dict.items(): # check for key, value from geeting dictionary\n",
    "        if(re.search(pattern,user_response)):  # Using regex to find out, if value matches with user response\n",
    "            matched_intent = intent           \n",
    "            if matched_intent in responses:\n",
    "                key = matched_intent\n",
    "                break\n",
    "\n",
    "    # print the pre written response based on keyword found in the user input\n",
    "    print('[Eliza]: ',random.choice(responses[key]))         \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace function\n",
    "\n",
    "Function is used to replace words in user response such as I'm to I am or I've to I have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function is used to replace words like I'm to I am\n",
    "\n",
    "def replace(text):\n",
    "    text = re.sub(\"\\'t\",\" not\", text)\n",
    "    text = re.sub(\"\\'m\",\" am\", text)\n",
    "    text = re.sub(\"\\'d\",\" would\", text)\n",
    "    text = re.sub(\"\\'ve\",\" have\", text)\n",
    "    text = re.sub(\"\\'ll\",\" will\", text)\n",
    "    text = re.sub(\"\\'re\",\" are\", text)\n",
    "    text = re.sub(\"\\'s\",\" is\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronoun Conversion function\n",
    "\n",
    "The function will convert pronoun used in the user's statement(I to you or are to am) and integrates it to the Eliza response and returns to the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement dictionary is used to replace first person to second person\n",
    "replacements = {'i': 'you',\n",
    "                'you':'I',\n",
    "                'me': 'you',\n",
    "                'my': 'your',\n",
    "                'am': 'are',\n",
    "                'are': 'am'\n",
    "                }\n",
    "\n",
    "def pronoun_conversion(text):\n",
    "    tokens = word_tokenize(text.lower()) \n",
    "    \n",
    "    # go through list of tokens to replace words seen in the dictonary of replacements\n",
    "    for i , token in enumerate(tokens):\n",
    "        if token in replacements:\n",
    "            tokens[i] = replacements[token]\n",
    "            \n",
    "    # put the values into a format to put into commands       \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_user_input(user_response):\n",
    "    #replace contraction words with their elongated format e.g you're becomes you are\n",
    "    if(re.search(r\"[A-Za-z]'(m|d|t)\",user_response)): # replacing 't to not and so on'\n",
    "        text = replace(user_response)\n",
    "    else:\n",
    "        text = user_response\n",
    "        \n",
    "    text = pronoun_conversion(text) # it will call pronoun function\n",
    "    \n",
    "    #returns the elongated form of contration word\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responses basic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of repsonse with the field for .format() to enter word tagged via the nltk.pos_tag that is either a JJ ,NN ,VBP, VN , or personal pronoun\n",
    "\n",
    "answers_feel = {\n",
    "\n",
    "        r'.*(feel).*':[r\"I am sorry to hear about you feeling {}.\",r\"Any idea why you are feeling like {} ?\"],\n",
    "\n",
    "        r'(.*)(crave).*':[r\"Any reason why you crave {}\",r\"Do you want to tell me, why you crave {} ?\"],\n",
    "\n",
    "        r'.*(like).*':[r\"I see you really like {}\",r\"Is there a reason you like {}?\"],\n",
    "\n",
    "        r'.*(can\\'t).*':[r\"How do you know you can't {} .?\", r\"Perhaps you could {} if you tried.\"],\n",
    "\n",
    "        r'.*(happy).*':[r\"That is good that {} is making you happy?\",r\"I am glad {} makes you happy, any idea as to why it does?\"],\n",
    "\n",
    "        r'.*(sad).*':[r\"Sorry to hear that {} is making you sad, tell me more.\",r\"Is there a particuler reason {} makes you sad?\"],\n",
    "\n",
    "        r'.*(angry).*':[r\"Sorry to hear that {} is making you angry. Let's discuss further?\",r\"Do you know why {} makes you so angry?\"],\n",
    "\n",
    "        r'.*(desire).*':[r\"What would it mean to you if you got {} ?\", r\"What is the real reason behind {} ?\"],\n",
    "\n",
    "        r'.*(was I).*':[r\"What if you were {} ?\", r\"Do you think you were {} ?\"],\n",
    "\n",
    "        r'.*(remember).*':[r\"Do you often think about {} ?\", r\"Does thinking of {} bring anything else to mind?\"],\n",
    "\n",
    "        r'.*(if).*':[r\"Do you think that its likely that {} will occur?\", r\"Do you wish that {}?\"],\n",
    "\n",
    "        r'(.*)':[r\"I do not understand. Could you please type again?\",\n",
    "                          r\"I do not understand. Please elaborate\",\n",
    "                         r\"I am trouble following you. Could you please elaborate.\"]\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responses_basic_questions(intent):\n",
    "    user_response = input().lower()\n",
    "    response_word = \"\"\n",
    "    value =\"\"\n",
    "    exit_words =(r'.*(exit|bye|quit).*')\n",
    "    \n",
    "    pattern =re.match(exit_words,user_response)\n",
    "    flag = True\n",
    "    \n",
    "    # if the person enters an exit word at this point then we need to jump out of the function.\n",
    "    \n",
    "    if(pattern):\n",
    "        print('[Eliza]: Bye! Take care')\n",
    "        flag = False       \n",
    "        return flag\n",
    "\n",
    "    # idenitfy the keyword that was passed by the user as it is either a NN, VBP, or JJ\n",
    "    #tokenize the word and sent so we can parse through in a clean way\n",
    "    sentences = nltk.sent_tokenize(user_response)\n",
    "    words = nltk.word_tokenize(user_response)\n",
    "    \n",
    "    #if given a one word response try and switch the topic as we assume they dont want continue this topic\n",
    "    if(len(words)) == 1:\n",
    "        print('[Eliza]: Lets switch to something else')\n",
    "        return flag\n",
    "\n",
    "     \n",
    "    for sentence in sentences:\n",
    "        words = [word for word in nltk.word_tokenize(sentence)]\n",
    "\n",
    "    #tag the words with the pos tag to get what kind of speech topic they are\n",
    "    tagged = nltk.pos_tag(words)\n",
    "\n",
    "     #loop through the words to determine word to use in the built in sentance\n",
    "    for (word, tag) in tagged:\n",
    "        if tag == 'PRP' or tag == 'PRP$':# If the word is a proper noun\n",
    "            if word in replacements:\n",
    "                pr_noun = pronoun_conversion(word)\n",
    "            else:\n",
    "                pr_noun = word\n",
    "\n",
    "        if tag == 'VB' or tag == 'JJ' or tag == 'VBP' or tag == 'NN' :\n",
    "            if(re.search(intent,word)):\n",
    "                response_word = ''\n",
    "            else:\n",
    "                response_word = \"{}\".format(word)\n",
    "\n",
    "  #based on the users answer to prompt take what they answered and give a response\n",
    "    for intent,pattern in answers_feel.items():\n",
    "        if(re.search(intent, user_response)):\n",
    "            t1 = random.choice(answers_feel[intent])\n",
    "            if intent != \"(.*)\":\n",
    "                value = re.sub(intent,t1,user_response)\n",
    "                value = (value.format(response_word))\n",
    "                break\n",
    "            else: #if doesnot match with the answer_feel dictionary\n",
    "                value = t1\n",
    "                break\n",
    "\n",
    "   #print out the value with response from the system and kick out of the funtion back into the while loop if the flag has not changed\n",
    "    print ('[Eliza]: ', end=\"\")\n",
    "    print(value)\n",
    "    \n",
    "    return flag\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation function\n",
    "\n",
    "Function will take the user intent derived from the user_input and generate a reponse based on the users input related more variable responses along with handling the wanting to stop communciation with an exit. Will also be calling the responses_basic_questions function and pass it an intent it knows it can handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## user conversation\n",
    "\n",
    "\n",
    "def conversation(user_name):\n",
    "    exit_words =(r'.*(exit|bye|quit).*')\n",
    "\n",
    "    global flag\n",
    "    flag = True;\n",
    "    \n",
    "    #run until the user does enter an exit word.\n",
    "    while(flag == True):\n",
    "        user_response = input().lower()\n",
    "        pattern =re.match(exit_words,user_response)\n",
    "\n",
    "        #exit if the stopwords have been used\n",
    "        if(pattern):\n",
    "            print('[Eliza]: Bye {} ! Take care'.format(user_name))\n",
    "            flag = False;                       \n",
    "            \n",
    "        else:\n",
    "            user_response = replace_user_input(user_response)\n",
    "            #run through the list of response eliza knows how to respond to and genrate a small response\n",
    "            for intent,pattern in pyscoresponses.items():\n",
    "                match = re.search(intent, user_response)\n",
    "                if match:\n",
    "                    response= random.choice(pyscoresponses[intent])\n",
    "                    \n",
    "                    #if there is in the response a tag of \\d replace it based on location with re.sub function\n",
    "                    if re.search('\\d',response):\n",
    "                        value = re.sub(intent,response,user_response)\n",
    "                        #print out generated response \n",
    "                        print('[Eliza]: ',value)\n",
    "                        \n",
    "                        #check for key match that responses_basic_questions can handle.\n",
    "                        for key,value in answers_feel.items():\n",
    "                            if re.search(key,intent):\n",
    "                                flag = responses_basic_questions(key)\n",
    "                                break\n",
    "                        break\n",
    "                    else:\n",
    "                        print('[Eliza]: ',response)\n",
    "                        break\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "\n",
    "The starting point of the program. The function will call all other functions in the defined order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    user_name = username()\n",
    "    greeting(user_name)\n",
    "    conversation(user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eliza]: Hi I am psychotherapist! What is your name?\n",
      "My name is sup\n",
      "[Eliza]: Hi Sup, how are you feeling?\n",
      "bemused\n",
      "[Eliza]:  I am sorry to hear that. Feeling lost can be a painful experience. How can I help you\n",
      "I need you\n",
      "[Eliza]:  Are you sure you need I?\n",
      "yes\n",
      "[Eliza]: Lets switch to something else\n",
      "I crave power\n",
      "[Eliza]:  Do you really crave power?\n",
      "yes I really crave power\n",
      "[Eliza]: Any reason why you crave power\n",
      "no\n",
      "[Eliza]:  Why no?\n",
      "I don't know\n",
      "[Eliza]:  Are you sure?\n",
      "tell me about you\n",
      "[Eliza]:  We are discussing you, not me.\n",
      "ok\n",
      "[Eliza]:  Sounds good! Tell me more about you?\n",
      "bye\n",
      "[Eliza]: Bye Sup ! Take care\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
