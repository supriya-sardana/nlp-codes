{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This is a question answering system that is developed in Python. The system is only able to answer 'Who', 'What', 'Where' and 'When' questions. The question answering system is not domain specific and provides answers in complete sentences only if user question matches with the system pre defined format. If system does not know the answer to user questions, then it simply returns with default answer that is \"I am sorry, I don't know the answer.\". And if system is able to find out the output from wikipedia then it returns the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "Welcome to Question Answering system\n",
    "\n",
    "This is a QA system by Team1. It will try to answer questions that start with Who, What, When or Where.\n",
    "\n",
    "Please enter exit to leave the Q&A session\n",
    "\n",
    "Who is Joe Biden? (question)\n",
    "\n",
    "Joe Biden is the 46th and current president of the United States. (system answer)\n",
    "\n",
    "who was APJ Abdul Kalam? (question)\n",
    "\n",
    "APJ Abdul Kalam was an Indian aerospace scientist who served as the 11th President of India from 2002 to 2007. (system answer)\n",
    "\n",
    "When was Beyonce born? (question)\n",
    "\n",
    "Beyonce Born was born on January 4 1954. (system answer)\n",
    "\n",
    "Where is United States of America? (question)\n",
    "\n",
    "United America is a country primarily located in North America. (system answer)\n",
    " \n",
    "bye\n",
    "\n",
    "Thank you for your time! Goodbye.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "Step 1. System welcome the user with pre-defined welcome message.\n",
    "\n",
    "Step 2. System enters the while loop and decides the next course of action based on the user input.\n",
    "\n",
    "        - Option 1: If the user wants to quit:\n",
    "                    System reponds with the \"Thank you for your time! Goodbye.\" and exit the program.\n",
    "                    \n",
    "        - Option 2: If the user wants to continue the conversation:\n",
    "\n",
    "                    Step 1. User enters the question and system will match the question with the pre defined format using regrex.\n",
    "\n",
    "                    Step 2. If the question is not related to 'Who', 'What', 'Where' and 'When', system will return \"Please only ask Who, What, When \n",
    "                    and Where question.\"\n",
    "\n",
    "                    Step 3. If the question matches with the existing format, system will perform below steps:\n",
    "\n",
    "                            a. Tokenize the words, check for POS tags and store the noun and verb phrases in a seprate list.\n",
    "                            b. Who, what and where question type, uses same function to find out the answer. When question uses \n",
    "                            different function to find out the answer.               \n",
    "                            c. Search the wikipedia with the noun phrase using wikipedia library.\n",
    "                            d. Search the sentences for getting relevant answer using verb phrases and regular expression.\n",
    "                            e. Returns the relevant answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import en_core_web_sm\n",
    "import wikipedia\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating logging object\n",
    "\n",
    "\n",
    "\n",
    "log_file = sys.argv[1]\n",
    "\n",
    "logging.basicConfig(filename = log_file, level = logging.DEBUG, format = '%(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will parse the user question and return the answer back to user\n",
    "\n",
    "def get_answer(question):\n",
    "    \n",
    "    wh_question_list = ['who','what','when','where']\n",
    "    question_list = r'('+'|'.join(wh_question_list)+')'  \n",
    "    \n",
    "    verb_list = ['is','am','you','was','did','are','were','has','have','does']\n",
    "    verb_list_temp = r'('+\"|\".join(verb_list)+')'\n",
    "    \n",
    "    rest_body = r'(.*)'\n",
    "    \n",
    "    parseQuestion = re.search( \" \".join([question_list,verb_list_temp,rest_body]), question, re.IGNORECASE) #Checking the question format\n",
    "    logging.info(\"Prase Question is: %s\", parseQuestion)\n",
    "    \n",
    "    if(parseQuestion): #If question format matches correctly, function will go to the rest part\n",
    "        \n",
    "        question_type = parseQuestion[1]  # Checking QuestionType\n",
    "        verb_type = parseQuestion[2]      # Storing Verb from the question\n",
    "        rest_body = parseQuestion[3]      # Storing remaining body\n",
    "        \n",
    "        ## Extracting the noun and the verb phase from the rest body    \n",
    "        pos_tags = nltk.pos_tag(nltk.word_tokenize(rest_body))\n",
    "        \n",
    "        ## Getting pronoun or noun phrase from the rest_body and storing in noun_phrase variable\n",
    "        noun_phrase = \" \".join(word[0] for word in pos_tags if word[1]=='NN' or word[1]=='NNS' or word[1]=='NNP')\n",
    "        \n",
    "        ## Getting only verb phrase from the rest_body and storing in verb_phrase variable\n",
    "        verb_phrase = \" \".join(word[0] for word in pos_tags if word[1]=='VBN' or word[1]=='VBD')\n",
    "        \n",
    "        if(question_type.lower() != 'when'):  #if the question type is where, what and why\n",
    "            answer = get_answer_what_question(noun_phrase, verb_phrase, verb_type)\n",
    "            return answer\n",
    "        \n",
    "        else: # If question type is when\n",
    "            answer = get_answer_when_question(noun_phrase, verb_phrase, verb_type,question )\n",
    "            return answer\n",
    "    \n",
    "    elif(re.search(question_list,word_tokenize(question)[0]) is not None): # If question format doesnt matches, default statement will be passed\n",
    "        statement = 'Please enter valid question.'\n",
    "        return statement\n",
    "        \n",
    "    else: # If question is other than 'Wh' questions.\n",
    "        statement = 'Please only ask Who, What, When and Where question.'\n",
    "        return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defined to find out answer for 'when' question\n",
    "\n",
    "def get_answer_when_question(noun_phrase,verb_phrase, verb_type, question):\n",
    "    \n",
    "    wiki_findings = []  #List to store the findings from the wiki pages\n",
    "    \n",
    "    birth_list = r'(birthday|birth day|birth|born)'  # Birth day patterns\n",
    "    death_list = r'(died|die|death|killed|passed away)'   # Death type paterrns\n",
    "    \n",
    "    if(re.search(birth_list,question,re.IGNORECASE)):  # Loop for finding birth date\n",
    "        sentences = wikisearch(noun_phrase) #Calling wikisearch function\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if(re.search(verb_phrase, sentence, re.IGNORECASE) is not None):\n",
    "                wiki_findings.append(sentence)\n",
    "                            \n",
    "        # Pattern to match born date like Jan 12, 1990 or mmddyyyy or 12 Jan 2001\n",
    "        birth_pattern = r'''((\\d{1,2}\\d{1,2}\\d{2,4}\\W*) | (\\d{1,2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{2,4}\\W*) | ((Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{1,2},? \\d{2,4}\\W*) | (\\d{4} to \\d{4}\\W*))'''\n",
    "        \n",
    "        if(len(wiki_findings)>0):\n",
    "            finding = wiki_findings[0]\n",
    "            logging.info('\\n Finding is:\\n %s',finding)\n",
    "            birth_date = re.search(birth_pattern,finding, re.IGNORECASE)\n",
    "        \n",
    "        \n",
    "            if(birth_date != None):  # If birthdate matches with the birth_pattern\n",
    "            \n",
    "                try:\n",
    "                    birth_date = birth_date.group(1)\n",
    "                    name = noun_phrase.split()\n",
    "            \n",
    "                    if ')' in birth_date: # Checking if teh birth date contaings ')'\n",
    "                        birth_date = birth_date.split(')')\n",
    "                        birth_date=birth_date[0]\n",
    "\n",
    "                    # Defining answer that need to send back to user\n",
    "                    answer = name[0].capitalize() + \" \" + name[1].capitalize() + ' was born on ' + re.sub(r',|\" \"','',birth_date).rstrip() + \".\"\n",
    "                    return answer\n",
    "\n",
    "                except:\n",
    "                     return \"I am sorry, I don't know the answer.\"\n",
    "            \n",
    "            else:\n",
    "                return \"I am sorry, I don't know the answer.\"\n",
    "              \n",
    "            \n",
    "        else:\n",
    "            return \"I am sorry, I don't know the answer.\"\n",
    "            \n",
    "            \n",
    "     \n",
    "    \n",
    "    elif(re.search(death_list, question, re.IGNORECASE)): # Loop for finding death date\n",
    "        \n",
    "        sentences = wikisearch(noun_phrase) # Calling wikisearch function\n",
    "        \n",
    "        # Pattern to match death date, Jan 12, 1990 or 12 Jan 2001\n",
    "        death_pattern = r'''(((Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{1,2},? \\d{2,4}\\s*–\\s*(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{1,2}(,)?) \\d{2,4}|(\\d{1,2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{2,4}\\s*–\\s*\\d{1,2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\w* \\d{2,4}))'''\n",
    "        \n",
    "        if(len(sentences)>0):\n",
    "            wiki_findings = sentences[0] # Using only first line to find out the answe\n",
    "            logging.info('\\n Finding is:\\n %s',wiki_findings)#Logging the result\n",
    "     \n",
    "         \n",
    "        \n",
    "            death_date = re.search(death_pattern,wiki_findings, re.IGNORECASE) # Searching the death pattern in wikipedia result using regex\n",
    "\n",
    "            if(death_date != None): # If death date matches the pattern\n",
    "\n",
    "                try:\n",
    "                    name = noun_phrase.split()\n",
    "\n",
    "                    date = death_date.group(0).split('–')  #death date will contain \"February 22, 1732 – December 14, 1799\", we will use date December 14, 1799 as death date\n",
    "\n",
    "                    # Defining answer that need to send back to user\n",
    "                    answer = name[0].capitalize() + \" \" + name[1].capitalize() + ' died on ' + date[-1] + \".\"\n",
    "                    return answer\n",
    "\n",
    "                except:\n",
    "                    return \"I am sorry, I don't know the answer.\"\n",
    "\n",
    "            else:\n",
    "                return \"I am sorry, I don't know the answer.\"\n",
    "            \n",
    "        else:\n",
    "            return \"I am sorry, I don't know the answer.\"\n",
    "        \n",
    "    else: # other than birth and death dates\n",
    "        \n",
    "        #Search for synonyms of verb_phrase\n",
    "        syns = [lemma.name() for syn in wordnet.synsets(verb_phrase) for lemma in syn.lemmas()]\n",
    "        \n",
    "        sentences = wikisearch(noun_phrase) #Calling wikisearch function\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if(re.search('('+verb_phrase+'|'.join(syns)+')', sentence, re.IGNORECASE) is not None):\n",
    "                wiki_findings.append(sentence)     #Searching wikipedia\n",
    "                logging.info('%s \\n',wiki_findings)      #Logging the result\n",
    "                \n",
    "        if(len(wiki_findings)>0):\n",
    "            \n",
    "                try:\n",
    "                    finding = wiki_findings[0]\n",
    "                    match = re.search(r'\\d{4}',finding, re.IGNORECASE)\n",
    "\n",
    "                    if(match is not None):\n",
    "                        answer = noun_phrase.capitalize() + \" \" + verb_type + \" \"+ verb_phrase + \" on \" + match.group(0) + \".\"\n",
    "                        return answer\n",
    "\n",
    "                    else:\n",
    "                        return \"I am sorry, I don't know the answer.\"\n",
    "                    \n",
    "                except:\n",
    "                    return \"I am sorry, I don't know the answer.\"\n",
    "        else:\n",
    "            return \"I am sorry, I don't know the answer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find out answer for what, where and who question\n",
    "\n",
    "def get_answer_what_question(noun_phrase,verb_phrase, verb_type):\n",
    "\n",
    "    wiki_findings = []  #List to store all the findings from the wiki pages\n",
    "        \n",
    "    if(noun_phrase): # If noun is present in the question, wikipedia is search using noun words\n",
    "        sentences = wikisearch(noun_phrase)  # Calling wikisearch function and passing noun(s) in the arguments\n",
    "\n",
    "        answer=[]  #it will store answer that need to return to user\n",
    "            \n",
    "        if(verb_phrase and sentences != None): # If verb_phrase exist and sentences not equals to Null\n",
    "            for sentence in sentences:\n",
    "                if(re.search(verb_phrase, sentence, re.IGNORECASE) is not None): \n",
    "                    wiki_findings.append(sentence)   # Storing all the sentences that matches the verb phrase passed in the quesion\n",
    "                    logging.info('\\n Wiki finding is:\\n %s',wiki_findings)\n",
    "                \n",
    "            if(len(wiki_findings)>0):\n",
    "                finding = wiki_findings[0] # Using only first result\n",
    "                logging.info('\\n Finding is:\\n %s',finding) \n",
    "\n",
    "                match = re.search(r'(.*)'+ '( '  + verb_phrase + ' )' + '(.*)',finding)\n",
    "                    \n",
    "                try:\n",
    "                    if(match is not None):\n",
    "                        match_result = match.group(3)\n",
    "\n",
    "                        # forming answer\n",
    "                        answer = noun_phrase.capitalize() + \" \" + verb_type + \" \"+ verb_phrase + \" \" + match_result \n",
    "                        return answer\n",
    "                    \n",
    "                    elif(verb_type and sentences != None): # If verb_type exist and sentences not equals to Null\n",
    "                        wiki_findings=[]\n",
    "                        \n",
    "                        for sentence in sentences:\n",
    "                            if(re.search(verb_type, sentence, re.IGNORECASE) is not None): #Search with verb_type\n",
    "                                wiki_findings.append(sentence)   # Storing all the sentences that matches the verb type passed in the quesion\n",
    "                                logging.info('\\n Wiki finding is:\\n %s',wiki_findings)\n",
    "                                \n",
    "                        if(len(wiki_findings)>0):\n",
    "                            finding = wiki_findings[0]\n",
    "                            logging.info('\\n Finding is:\\n %s',finding)\n",
    "                                \n",
    "                            match = re.search(r'(.*)'+ '( '  + verb_type + ' )' + '(.*)',finding)\n",
    "                            \n",
    "                            if(match is not None):\n",
    "                                # forming answer\n",
    "                                answer= noun_phrase.capitalize() + \" \" + verb_type + \" \" + match.group(3) \n",
    "                                return answer\n",
    "                                \n",
    "                            else:\n",
    "                                return \"I am sorry, I don't know the answer.\" \n",
    "                        else:\n",
    "                                return \"I am sorry, I don't know the answer.\"\n",
    "                    else:\n",
    "                        return \"I am sorry, I don't know the answer.\"\n",
    "                        \n",
    "                except:\n",
    "                    return \"I am sorry, I don't know the answer.\"\n",
    "                        \n",
    "            else:\n",
    "                return \"I am sorry, I don't know the answer.\"\n",
    "      \n",
    "            \n",
    "        elif(verb_type and sentences != None): # If verb_type exist and sentences not equals to Null\n",
    "            for sentence in sentences:\n",
    "                if(re.search(verb_type, sentence, re.IGNORECASE) is not None): #Search with verb_type\n",
    "                    wiki_findings.append(sentence)   # Storing all the sentences that matches the verb type passed in the quesion\n",
    "                    logging.info('\\n Wiki finding is \\n: %s',wiki_findings)\n",
    "                        \n",
    "            if(len(wiki_findings)>0):\n",
    "                finding = wiki_findings[0]\n",
    "                logging.info('\\n Finding is:\\n %s',finding)\n",
    "\n",
    "                match = re.search(r'(.*)'+ '( '  + verb_type + ' )' + '(.*)',finding)\n",
    "                    \n",
    "                try:\n",
    "                    if(match is not None):\n",
    "                        # forming answer\n",
    "                        answer= noun_phrase.capitalize() + \" \" + verb_type + \" \" + match.group(3) \n",
    "                        return answer\n",
    "                        \n",
    "                    else:\n",
    "                        return \"I am sorry, I don't know the answer.\" \n",
    "                        \n",
    "                except:\n",
    "                    return \"I am sorry, I don't know the answer.\"\n",
    "                    \n",
    "            else:\n",
    "                return \"I am sorry, I don't know the answer.\"  \n",
    "                                \n",
    "        else: \n",
    "            return \"I am sorry, I don't know the answer.\"\n",
    "    \n",
    "    else: \n",
    "        return \"I am sorry, I don't know the answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is used to fetch data from wikipedia using wikipedia library\n",
    "\n",
    "def wikisearch(searchterms):\n",
    "    \n",
    "    wiki_result = wikipedia.search(searchterms)\n",
    "    \n",
    "    try:\n",
    "        firstresult = wiki_result[0]  # Extracting information from the first page\n",
    "        logging.info(\"The first result from wikipedia: %s\",firstresult)  # Logging first result got from wikipedia\n",
    "        \n",
    "        # Extracting contect from the first matching page\n",
    "        page_content = wikipedia.page(firstresult, auto_suggest=False).content\n",
    "        \n",
    "        if(page_content):\n",
    "            sentences = sent_tokenize(page_content) # Tokenizing the sentences and returning back to the calling function\n",
    "        else:\n",
    "            sentences = None\n",
    "        \n",
    "    except wikipedia.DisambiguationError as e: # Handling DisambiguationError error\n",
    "        firstresult = wiki_result[1]  # Extracting information from the second page\n",
    "        logging.info(\"The first result from wikipedia: %s\",firstresult)  # Logging second result got from wikipedia\n",
    "        \n",
    "        # Extracting contect from the first matching page\n",
    "        page_content = wikipedia.page(firstresult, auto_suggest=False).content\n",
    "        \n",
    "        if(page_content):\n",
    "            sentences = sent_tokenize(page_content) # Tokenizing the sentences and returning back to the calling function\n",
    "        else:\n",
    "            sentences = None\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function of system\n",
    "\n",
    "def main():\n",
    "    \n",
    "    exit_words = ['bye','Good bye','exit','quit']\n",
    "    \n",
    "    Flag = True\n",
    "    \n",
    "    # Welcome screen message\n",
    "    print(\"Welcome to Question Answering system\")\n",
    "    print('''This is a QA system by Team1. It will try to answer questions that start with Who, What, When or Where.''')\n",
    "    print(\"Please enter exit to leave the Q&A session\")\n",
    "    logging.info(\"==========QA-System Start==========\")\n",
    "\n",
    "\n",
    "    while(Flag==True):  \n",
    "        user_question = input() # Taking user question\n",
    "        \n",
    "        logging.info(\"\\n User Question: %s \",user_question) # Logging user question\n",
    "        \n",
    "        exitword = re.search(r'(.*)([b|B]ye|[E|e]xit|[Q|q]uit)(.*)',user_question)  # Exit system if user enters exit words\n",
    "    \n",
    "        if exitword:\n",
    "            print(\"Thank you for your time! Goodbye.\")\n",
    "            logging.info(\"Thank you for your time! Goodbye.\")\n",
    "            \n",
    "            Flag = False\n",
    "            \n",
    "        else:\n",
    "            response = get_answer(user_question)\n",
    "            \n",
    "            logging.info(\"\\n System response: %s\",response) # logging answer\n",
    "            print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Question Answering system\n",
      "This is a QA system by Team1. It will try to answer questions that start with Who, What, When or Where.\n",
      "Please enter exit to leave the Q&A session\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Who is Emily Dickinson?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, I don't know the answer.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for your time! Goodbye.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
